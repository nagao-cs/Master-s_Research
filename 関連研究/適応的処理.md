## Adaptive NMS: Refining Pedestrian Detection in a Crowd

URL: https://openaccess.thecvf.com/content_CVPR_2019/papers/Liu_Adaptive_NMS_Refining_Pedestrian_Detection_in_a_Crowd_CVPR_2019_paper.pdf

### 課題
+ NMSはグラウンドトゥルースインスタンスが近くにある場合、TPを減らしてしまう

### 仮説
+ グラウンドトゥルースの密度に応じてNMSの閾値を変化させることで、密度が高い場面でもTPを高く保ちつつ余計なFPを減らすことができる

### 手法
+ 密度の推定をする層を構築
+ 推定された密度に基づいてAdaptive-NMSを用いて物体検出をする

## Real-time adaptive object detection and tracking for autonomous vehicles
URL: C:\Users\owner\Documents\LabSD\Maser-s_Research\関連研究\hoffmann2020autonomous.pdf
### 課題（Problem）
+ 自動運転車では、物体検出と追跡をリアルタイムで正確に行う必要がある。
+ しかし、近年の高精度なディープニューラルネットワーク（DNN）は層が深くなりすぎ、推論速度が遅くなるという課題がある。
+ 特に、交通環境のように動的で複雑な場面では、精度と速度の両立が難しい。
+ そのため、処理時間を抑えつつリアルタイム性を維持し、かつ高い精度を実現する適応的な検出・追跡システムが求められる。

### 仮説（Hypothesis）
+ 物体検出と追跡を組み合わせ、環境の状態（例えば検出された物体数）に応じて動作モードを切り替える“マルチステージ適応システム”を構築すれば, リアルタイム性を維持しながら高精度な物体検出・追跡が可能になる。

### 手法（Method）

+ 構成：YOLOv3を用いた物体検出ステージと、HART（Hierarchical Attentive Recurrent Tracking）を用いた追跡ステージを組み合わせたマルチステージ構造。
+ Adaptive Stage Shift System：
    フレームごとの検出物体数に応じて、検出ステージと追跡ステージの切り替えを自動制御。
    物体数が少ないときは追跡（低計算負荷）、多いときは検出（高精度）を選択。

### 結果（Results）
+ 車クラスでYOLOv3が最高（約43% AP）だが、提案手法もほぼ同等（約41%）。
+ 歩行者クラスでは、提案手法がSSD-300を上回る精度を示した。
+ 速度：
    提案手法（Adaptive 1/1）はYOLOv3よりも約49%高速。
    構成によっては最大76%のフレームレート向上を達成。
+ 動作傾向：
    交通密度が高いときは検出中心、低いときは追跡中心で処理時間が短縮。
    様々な交通条件下でリアルタイム動作を維持。

### 考察（Discussion）
+ 提案システムは「精度と速度のトレードオフ」を効果的に制御できる。
+ YOLOv3単体と比べ、やや精度が低下する場面もあるが、リアルタイム性を重視する自動運転などの応用において実用的。
+ 適応切替によって計算資源を効率的に活用でき、交通状況に応じた最適動作を自動で実現できる点が特徴。

## Adaptive Inference through Early-Exit Networks: Design, Challenges and Directions
URL: https://dl.acm.org/doi/pdf/10.1145/3469116.3470012
### 課題
従来の深層ニューラルネットワークは固定された深さで全層を通して推論を行うため、推論計算コストが大きく、特にリソース制約のある環境（モバイルやエッジデバイス）で迅速かつ省エネルギーな推論が求められる課題がありました。
しかし、すべての入力データについて同一の計算を行うのは非効率で、多くの「容易な入力」は浅い層までの計算で十分に分類・識別可能です。

### 研究内容と手法
+ Early-Exit Networksの提案
ネットワークのいくつかの中間層に「出口（exit）」を設け、推論時にその出口で十分な信頼度が得られた時点で計算処理を終了できるようにする構造。これにより、入力ごとに異なる層深さまで推論を行う「可変深度推論」が可能になる。

+ 各出口の信頼度判定
中間層からの推論結果に対して信頼度（確信度）を計算し、閾値を超えれば以降の層を通さずに推論結果を出す。閾値は性能とコストのトレードオフに応じて調整。

+ 効率的な出口設計と学習
中間層の出口は別途分類器として訓練され、ネットワーク全体の精度を維持しながら早期終了率を高めることが可能。

### 実験と成果
画像分類タスクなど複数のベンチマークで実験し、early exitにより計算量の大幅削減（推論時間の短縮）とエネルギー消費削減を実現。
全層推論の計算コストを最大で40～60%カットしつつ、分類精度はほぼ維持。
入力の難易度や複雑さに応じた柔軟な計算リソース割り当てが可能になった点を示しました。

## Adaptive Inference: Theoretical Limits and Unexplored Opportunities
URL: https://arxiv.org/pdf/2402.04359
### 研究課題（問題設定）
大規模・高性能なニューラルネットワークは推論性能（精度）で優れる一方、計算コストや消費エネルギーが非常に大きく、特に推論段階ではクラウドやエッジ環境での負荷が課題となっています。
既存の効率化技術（プルーニング・量子化・モデル蒸留など）は性能改善の伸びが頭打ちになっており、根本的な新技術の必要性が高まっています。
「アダプティブ推論」とは、入力データの難易度に応じて動的にモデルの大きさや計算量を調整することで、高精度を維持しつつ推論コストを大幅削減する手法ですが、これまでの研究は個別手法の提示が中心で、体系的理解や限界評価、理論的枠組みが不足していました。

### 解決のために行ったこと（研究の貢献）
理論的フレームワークの構築
アダプティブ推論を「状態空間（複数のバックボーンモデル群）」と「適応エージェント（入力ごとに最適モデルを選択する意思決定者）」という枠組みで抽象化。
理想的エージェント（Adaptive Oracle）を定義し、全モデルの精度と計算リソース情報を使って最適モデル選択戦略を形式化。

### 性能と効率の上界・下界の導出
適応エージェントが達成可能な性能（精度）と推論効率（節約できる計算量や消費電力）の理論的上限・下限の計算式を導出。
これにより、アダプティブ推論が理論的にどれくらい効率化可能か、どの程度の性能維持や向上が見込めるのかを定量評価可能に。

### 実験的評価
ImageNetの画像認識、HellaSwagの自然言語推論といった複数実データセットと複数モデルで検証。
実在のモデル（EfficientNet、ViT、Llama-2など）の性能・計算量から理論的効率改善ポテンシャルを算出。
数十倍〜数百倍に及ぶ推論効率の改善余地と、場合によっては性能の向上も可能であることを示した。

### 設計指針と改善提案
適応の状態空間設計（どのモデルを選択肢に入れるか、モデル数や性能分布）に関するガイドラインを示し、効果的なアダプティブ推論システム構築のための知見を提供。