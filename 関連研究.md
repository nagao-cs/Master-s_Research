## Object detectionのアンサンブル手法（複数の物体検出モデルを組み合わせる手法
### バイアスとバリアンス
+ バイアス：予測が実際の値からどの程度離れているか
+ バリアンス：予測がどの程度分散しているか

## アンサンブル学習
https://www.d.umn.edu/~rmaclin/cs5751/notes/opitz-jair99.pdf
### バギング
+ 高バリアンスで低バイアスの弱学習器に対して使用
+ 訓練データのノイズに対してロバスト性がある
+ 訓練セットのわずかな変更で予測が大きく変わる不安定な学習アルゴリズムに効果的

予測の平均値または多数決を採用し、より精度の高い推定値を算出。
回帰の場合は、個々の分類器が予測したすべての出力値から平均値を出力(ソフト投票)。
分類の場合は、最も多数派の分類を採用(ハード投票または多数決投票)

### ブースティング
+ 低バリアンスで高バイアスの弱学習器に対して使用
+ 過学習が発生しやすくなる
+ 弱学習器を繰り返し組み合わせて、より正確な結果を予測できる強学習器を構築する

ブースティングでは、以前の分類器によって誤分類されたデータが、次の学習器の学習で頻繁に選択される。これにより、新しい分類器は、現在のアンサンブルが苦手としている例をより正確に予測できるようになる。

### スタッキング
+ 複数のモデルの出力を新しい特徴量として組み合わせ、別のモデル（メタモデル）で最終的な予測を行う。

複数のモデル（例：モデルA、モデルB、モデルC）を訓練して予測を行う。
各モデルの予測結果を、新しいデータセットとしてまとめる。
そのデータセットを使ってメタモデル（ブレンダーとも呼ばれる）を訓練し、最終的な予測を行う。
異なるモデルの結果をまとめ、さらに別のモデルで最終予測を行う。

## BBoxの統合
### NMS
1. すべてのBBoxを信頼度順にソート
2. 最も高いBBoxと重複するBBoxを削除
3. 残りのBBoxに対して繰り返し実行

### SoftNMS
https://arxiv.org/pdf/1704.04503

### PRAE
https://arxiv.org/pdf/2105.03139
各検出モデルのBBoxの信頼度には差があるため、そのままアンサンブルすると性能低下の原因になる。各モデルの信頼度の差を統計的確率に変換することで解消する。
1. 複数の物体検出モデルを評価セットで物体検出を実行
2. 評価セットでの結果から、各BBoxが正しい確率を統計的に計算
3. テストセットで物体検出を実行
4. (2)で計算した確率を適用して、テストセットでのBBoxの信頼度を統計的確率に置き換え
5. (4)の統計的確率を重みとして複数のBBoxをNMSベースで融合
6. 複数のモデルの結果を融合したものを最終検出結果として出力

### WBF
https://arxiv.org/pdf/1910.13302
1. 各モデルからの予測を信頼度の降順にソートし、リストBを生成する
2. ボックスのクラスターと統合したボックス、それぞれのリストLとFを定義する
3. Bの各ボックスとFで一致するものがあるか調べる
4. 一致するものがあればFに対応するLのクラスターに追加
5. なけらばFとLに新しいエントリーを追加
6. 各クラスタについて、信頼度で重みづけしてボックスの平均座標を計算する
NMSでは一部のボックスが除外されるが、WBFではすべてのボックスが使用される

## 物体検出タスクの評価指標
